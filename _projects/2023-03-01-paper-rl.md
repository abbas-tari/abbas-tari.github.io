---
title: Reinforcement Learning-Based Switching Controller 
tags: paper
image: static/content/rl/sceneEE.png
shortdesc: (2023) for a milliscale robot in a constrained environment to autonomously move a ferromagnetic object representing a milliscale robot, around obstacles within a constrained environment in the presence of disturbances. 
---

<div class="justify-text">

## Description


In a world where minute robots (microrobots) hold the promise of revolutionizing various fields such as medicine, I embarked on a journey to create a controller that could autonomously navigate a tiny robot through challenging environments. Imagine a tiny robot maneuvering through the intricate pathways of the human body, delivering medicine with precision. This was the vision that fueled my endeavor as I dived into the realm of Reinforcement Learning (RL) to design a control mechanism for a milliscale robot in constrained spaces.

The tale begins in a simulated world, where I aimed to move a ferromagnetic object representing our tiny robot around obstacles amidst disturbances. The stage was set within a simplified model of a large intestine. The challenge was to ensure that the robot could find its way through without any direct manipulation, which could be hazardous.

The hero of our story is a novel RL-based switching controller, composed of two sub-controllers. The first sub-controller was like the eyes of our setup. It used the robot's inverse kinematic solutions to search for the ferromagnetic particle in the environment while remaining robust to disturbances. Once the particle was found, the second sub-controller, powered by a customized Rainbow algorithm, took charge. This sub-controller was the brain, controlling a robotic arm to carry the particle to a desired position through the constrained environment.

<img src="{{ site.url }}/static/content/rl/ERRT_v2.jpg" style="width:550px;height:auto;" alt="Image description" />

The Rainbow algorithm was trained in a realm of simulation, using a virtual replica of the UR5 robot arm. This training phase was crucial as it forged the intelligence that would later guide the robot in the real world. After rigorous training and testing in the simulated world, it was time to face the reality. The trained controller was transferred to a real UR5 robot to carry out the mission of transporting the ferromagnetic particle in a real-world scenario.

As the robot arm went about its task, every move was a testament to the countless hours of training and the seamless integration of the RL-based controller. The results were exhilarating! The success rate averaged 98.86% over 30 episodes for randomly generated trajectories. The robot was not only able to navigate through the constrained environment but also adept at handling unforeseen disturbances.

But the curiosity didn't end there. To put the RL-based mechanism to the test, I compared it with two classical path-finding approaches: Attractor Dynamics and execution extended Rapidly-Exploring Random Trees (ERRT). These tests confirmed that the RL-based method was not only comparable in performance but also more robust and ready to deploy in dynamic, complex environments.

This endeavor also marked the first time magnetic control of milli-sized ferromagnetic particles was achieved using an RL algorithm capable of avoiding obstacles and rejecting disturbances. The triumph was not just in devising a control scheme but in proving the viability of RL-based controllers for real-life applications, opening a doorway to endless possibilities.

As I delved deeper, exploring ERRT and Attractor Dynamics-based approaches, the RL-based algorithm continually showcased its robustness and adaptability. Unlike the ERRT method, which required a precise calibration with the environment and could struggle in real-time with complex or dynamic obstacles, the RL-based method was unfazed. It held its ground, promising a robust solution for navigating through ever-changing, dynamic environments.

In conclusion, this expedition illuminated the potential of RL in orchestrating the dance of tiny robots in constrained environments. The success of the RL-based controller in both simulated and real-world scenarios was a leap towards a future where minute robots could traverse the complex pathways of the human body or any constrained environment with finesse. The journey had its share of challenges, but the sight of the tiny robot, guided by the RL-based controller, navigating through the twists and turns with precision, was a spectacle of science meeting aspiration. This was not just a validation of the RL-based approach but a step closer to a world where tiny robots could embark on life-saving missions within the human body.

<div>


## <span id="Resources">Resources</span>

<a class="ieee-logo" href="https://ieeexplore.ieee.org/abstract/document/10081280/authors#authors">Link to</a>

[Download the Paper]({{ site.url }}/static/content/rl/paper.pdf)


